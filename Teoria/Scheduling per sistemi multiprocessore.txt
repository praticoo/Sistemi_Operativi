Fin qui la trattazione ha riguardato lo scheduling della
cpu in un sistema a processore singolo. Se sono disponibili più unità d’elaborazione, è possibile la distribuzione del carico, ma il problema dello scheduling diviene proporzionalmente più complesso. Si sono sperimentate diverse possibilità e, come s’è visto nella trattazione dello scheduling di una sola cpu, “la soluzione migliore” non esiste.

APPROCCI ALLO SCHEDULING PER MULTIPROCESSORI
una prima strategia di scheduling della
cpu per i sistemi multiprocessore affida tutte le decisioni, l’elaborazione dell’ I/o e altre attività del sistema a un solo processore, il cosiddetto master server.
Si tratta della multielaborazione asimmetrica, che riduce la necessità di condividere
dati grazie all’accesso di un solo processore alle strutture dati del sistema.
Quando invece ciascun processore provvede al proprio scheduling, si parla di
multielaborazione simmetrica. In questo caso i
processi pronti per l’esecuzione sono situati tutti in una ready queue comune, oppure
vi è un’apposita coda per ogni processore. In entrambi i casi, lo scheduler di ciascun
processore esamina la coda appropriata, da cui seleziona un processo da eseguire, l’accesso concorrente di più processori a una
struttura dati comune rende delicata la programmazione dello scheduler, al fine di
evitare che due processori scelgano il medesimo processo o che un processo in coda
non vada perso. 

PREDILEZIONE PER IL PROCESSORE
Si consideri che cosa accade alla memoria cache dopo che un processo sia stato eseguito da uno specifico processore: i dati che il processore ha trattato più recentemente
permangono nella cache e, di conseguenza, i successivi accessi alla memoria da parte
del processo tendono a utilizzare spesso la memoria cache. Si consideri ora che cosa
succede se un processo si sposta su un altro processore: i contenuti della memoria cache devono essere invalidati sul processore di partenza, mentre la cache del processore di arrivo deve essere nuovamente riempita. A causa degli alti costi di svuotamento e riempimento della cache, molti sistemi tentano di impedire il passaggio di processi da un processore all’altro, mirando a mantenere un processo sempre sullo
stesso processore. Si parla di predilezione per il processore, intendendo con ciò che un processo ha una predilezione per il processore su cui è in esecuzione.
La predilezione per il processore può assumere varie forme. Quando un sistema
operativo si propone di mantenere un processo su un singolo processore, ma non garantisce che sarà così, si parla di predilezione debole. In questo caso il
sistema operativo tenta di mantenere il processo su un singolo processore, ma è possibile che un processo migri da un processore all’altro. Alcuni sistemi dispongono di
chiamate di sistema per realizzare la predilezione forte, permettendo
così a un processo di specificare un sottoinsieme di processori su cui può essere eseguito. Molti sistemi supportano sia la predilezione debole che la predilezione forte.
Linux, per esempio, implementa la predilezione debole, ma fornisce anche il supporto della predilezione forte.

BILANCIAMENTO DEL CARICO
E'importante che il carico di lavoro sia distribuito equamente tra tutte
le unità elaborative per sfruttare appieno i vantaggi di avere più processori. Se ciò
non avviene, alcuni processori potrebbero restare inattivi mentre altri verrebbero intensamente sfruttati con una coda di processi in attesa. Il bilanciamento del carico
tenta di ripartire il carico di lavoro uniformemente tra tutti i processori di un sistema. Bisogna notare che il bilanciamento è necessario, di norma, solo nei sistemi in
cui ciascun processore ha una coda privata di processi eseguibili. Nei sistemi che
mantengono una coda comune, il bilanciamento del carico è sovente superfluo: un
processore inattivo passerà immediatamente all’esecuzione di un processo dalla coda
comune dei processi eseguibili. Va ricordato, tuttavia, che in quasi tutti i sistemi operativi attuali, ogni processore è effettivamente dotato di una
propria coda di processi eseguibili.
Il bilanciamento del carico può seguire due approcci: la migrazione push e la
migrazione pull. La prima prevede che un processo apposito controlli periodicamente il carico di ogni processore: se identifica uno sbilanciamento, riporta il carico in
equilibrio, spostando i processi dal processore saturo ad altri più liberi, o inattivi. La
migrazione pull, invece, si ha quando un processore inattivo prende un processo in
attesa a un processore sovraccarico. I due tipi di migrazione non sono mutuamente
esclusivi, e trovano spesso applicazione contemporanea nei sistemi con bilanciamento
del carico. Lo scheduler Linux, per esempio, si avvale di entrambe le tecniche.
Il vantaggio di poter eseguire un processo dall’inizio alla fine sul medesimo
processore è che in tal modo la memoria cache contiene i dati necessari per quel processo. Con la migrazione dei processi necessaria al bilanciamento del carico, questo
vantaggio si perde. Anche in questo frangente, come di consueto nell’ingegneria dei
sistemi, non vi sono regole che prescrivano una strategia ottimale: in alcuni sistemi,
un processore inattivo sottrae sempre un processo da un processore impegnato; in altri, i processi sono spostati solo se la disparità del carico supera una data soglia.